{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ykim879/whats.todays.trend/blob/master/revised_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bnx9G1CsJb4x"
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "def eachNewsHeadlines(ID, q):\n",
    "\tresponse = requests.get('https://newsapi.org/v2/top-headlines?sources=' + ID + '&apiKey=' + key)\n",
    "\tjson = response.json()\n",
    "\tif json['status'] != 'ok':\n",
    "\t\traise IOError('API key is probably overused :(')\n",
    "\ttopNews = []\n",
    "\ttopNews.append(ID)\n",
    "\tfor elem in json['articles']:\n",
    "\t\ttopNews.append(elem['title'])\n",
    "\tq.put(topNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Mcsm2sdtIlwS",
    "outputId": "5d5537ec-3342-43e5-e67e-ea18db85f414"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-246ea4a7b105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0;34m'language=en&country=us&'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \t\t\t   'apiKey=' + key)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sources'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "key = '5e74c7cf9e344e3e8c04210f9b75125b'\n",
    "response = requests.get('https://newsapi.org/v2/sources?'\n",
    "\t\t\t   'language=en&country=us&'\n",
    "\t\t\t   'apiKey=' + key)\n",
    "sources = response.json()['sources']\n",
    "df = pd.DataFrame();\n",
    "pd.set_option('display.max_columns', 7)\n",
    "for source in sources:\n",
    "  row = pd.Series(source)\n",
    "  df = df.append(row, ignore_index = True)\n",
    "df.set_index(\"name\", inplace = True)\n",
    "#collects headline\n",
    "threads = []\n",
    "q = queue.Queue()\n",
    "for id in df['id']:\n",
    "  t = threading.Thread(target = eachNewsHeadlines, args = (id, q))\n",
    "  threads.append(t)\n",
    "  t.start()\n",
    "for t in threads:\n",
    "  t.join()\n",
    "headlines = []\n",
    "while not q.empty():\n",
    "  headlines.extend(q.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "eKe1daeVJuS7",
    "outputId": "9460eb3b-1bbe-4682-8ce3-ae485b9f2082"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import matplotlib.pyplot as plt\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union({'says','news','new'})\n",
    "vectorizer = text.CountVectorizer(stop_words=stop_words, min_df=10)\n",
    "X = vectorizer.fit_transform(headlines)\n",
    "keywordDCT = sorted(vectorizer.vocabulary_.items(), key = lambda x:x[1], reverse = True)\n",
    "keywordDF = pd.DataFrame(keywordDCT, columns = ['keywords', 'counts'])\n",
    "print(keywordDF[:10])\n",
    "plt.bar(keywordDF['keywords'][:10], keywordDF['counts'][:10])\n",
    "plt.title('Top 10 Trends in News')\n",
    "plt.ylabel('# of Occurances in Headlines')\n",
    "plt.xlabel('Trends')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction import text\n",
    "import matplotlib.pyplot as plt\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "data = pd.read_csv('BBC News Train.csv')\n",
    "data = data.groupby('Category', sort=True)['Text'].apply(' '.join).reset_index()\n",
    "r,c = data.shape\n",
    "documents = []\n",
    "len_documents = []\n",
    "y_train = []\n",
    "for i in range(r):\n",
    "    document = str(data.loc[i,'Text'])\n",
    "    y_train.append(str(data.loc[i,'Category']))\n",
    "    len_documents.append(len(document))\n",
    "    documents.extend(document)\n",
    "documents.extend(keywords) #extend keywords\n",
    "#Form bag of words model using words used at least 10 times\n",
    "v = text.CountVectorizer(stop_words=stop_words, min_df = 10)\n",
    "print(documents)\n",
    "train = vectorizer.fit_transform(documents).toarray()\n",
    "x_train = []\n",
    "for i in len(len_documents) - 1:\n",
    "    x_train.append(train[:len_documents[i], :])#store in train_x\n",
    "gnb = GaussianNB()\n",
    "label = gnb.fit(data[x_train, y_train).predict(train[len_documents[-1]:])\n",
    "print(label)#X_test: keywords, x_train, y_train: trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMq3J20zyPQufW5ciWp0rRf",
   "include_colab_link": true,
   "name": "revised_news.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
